# app.py
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
from janome.tokenizer import Tokenizer
from wordcloud import WordCloud
import re

st.title("ğŸ“ è‡ªç”±è¨˜è¿°ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆåˆ†æã‚¢ãƒ—ãƒª")

# --- æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆï¼ˆWordCloudç”¨ï¼‰
FONT_PATH = "./static/fonts/ãƒ’ãƒ©ã‚®ãƒè§’ã‚´ ProN W6.ttc"  # é©å®œèª¿æ•´

# --- ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã¨åˆ†é¡èªå½™
tokenizer = Tokenizer()
excluded_verbs = {'ã™ã‚‹', 'ãªã‚‹', 'ã„ã‚‹', 'ã‚‰ã‚Œã‚‹', 'æ„Ÿã˜ã‚‹', 'ã‚„ã™ã„', 'ã›ã‚‹', 'ã‚ã‚‹'}
non_specific = re.compile(r"^\s*$|ã‚ã‹ã‚‰ãªã„|ç‰¹ã«ãªã—|ãªã—|ãªã„|ä¸æ˜")
category_keywords = {
    'ç¶­æŒ': ['ç¾çŠ¶ç¶­æŒ', 'ã“ã®ã¾ã¾', 'æº€è¶³', 'ç¶™ç¶š', 'è‰¯ã„', 'ã‚ã‚ŠãŒãŸã„'],
    'å¼·åŒ–': ['ã‚‚ã£ã¨', 'ã•ã‚‰ã«', 'å¼·åŒ–', 'æ‹¡å¤§', 'å¢—ã‚„ã™', 'æ·±ã‚ã‚‹'],
    'æ”¹å–„': ['æ”¹å–„', 'å¤‰ãˆã‚‹', 'èª²é¡Œ', 'ç›´ã™', 'å¯¾å¿œ', 'ä¸æº€', 'ã‚„ã‚ã¦', 'å›°ã‚‹']
}
positive_words = {'å¬‰ã—ã„', 'è‰¯ã„', 'ã‚„ã‚ŠãŒã„', 'æ¥½ã—ã„', 'æº€è¶³', 'åŠ©ã‹ã‚‹', 'å……å®Ÿ'}
negative_words = {'å›°ã‚‹', 'èª²é¡Œ', 'ä¸æº€', 'å¤§å¤‰', 'ç–²ã‚Œã‚‹', 'å•é¡Œ', 'ã‚¹ãƒˆãƒ¬ã‚¹'}

# --- é–¢æ•°
def tokenize(text):
    if pd.isna(text) or non_specific.match(text):
        return []
    text = re.sub(r'[^\wã-ã‚“ã‚¡-ãƒ³ä¸€-é¾¥]', '', str(text))
    tokens = []
    for token in tokenizer.tokenize(text):
        base = token.base_form
        pos = token.part_of_speech.split(',')[0]
        if pos in ['åè©', 'å‹•è©', 'å½¢å®¹è©'] and base not in excluded_verbs and len(base) > 1:
            tokens.append(base)
    return tokens

def classify_category(tokens):
    matched = {cat for cat, words in category_keywords.items() if any(t in words for t in tokens)}
    if not matched:
        return 'ä¸æ˜'
    elif len(matched) == 1:
        return list(matched)[0]
    else:
        return 'ãƒŸãƒƒã‚¯ã‚¹'

def judge_sentiment(tokens):
    pos = any(token in positive_words for token in tokens)
    neg = any(token in negative_words for token in tokens)
    if pos and not neg:
        return 'ãƒã‚¸ãƒ†ã‚£ãƒ–'
    elif neg and not pos:
        return 'ãƒã‚¬ãƒ†ã‚£ãƒ–'
    elif pos and neg:
        return 'ãƒŸãƒƒã‚¯ã‚¹'
    else:
        return 'ä¸­ç«‹'

def show_wordcloud(counter, title):
    wc = WordCloud(font_path=FONT_PATH, background_color='white', width=800, height=400)
    img = wc.generate_from_frequencies(counter)
    st.subheader(title)
    fig, ax = plt.subplots(figsize=(10, 5))
    ax.imshow(img, interpolation='bilinear')
    ax.axis('off')
    st.pyplot(fig)

# --- ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
uploaded_file = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type="csv")

if uploaded_file:
    df = pd.read_csv(uploaded_file)
    df['Q1_tokens'] = df['Q1å›ç­”'].apply(tokenize)
    df['Q2_tokens'] = df['Q2å›ç­”'].apply(tokenize)
    df['Q3_tokens'] = df['Q3å›ç­”'].apply(tokenize)
    df['all_tokens'] = df['Q1_tokens'] + df['Q2_tokens'] + df['Q3_tokens']

    df['category'] = df['all_tokens'].apply(classify_category)
    df['sentiment'] = df['all_tokens'].apply(judge_sentiment)

    # --- å±æ€§é¸æŠ
    org_col = df.columns[3]
    age_col = df.columns[4]
    gender_col = df.columns[5]

    st.sidebar.header("ğŸ“‚ ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°")
    org = st.sidebar.selectbox("çµ„ç¹”", ['ã™ã¹ã¦'] + df[org_col].dropna().unique().tolist())
    age = st.sidebar.selectbox("å¹´ä»£", ['ã™ã¹ã¦'] + df[age_col].dropna().unique().tolist())
    gender = st.sidebar.selectbox("æ€§åˆ¥", ['ã™ã¹ã¦'] + df[gender_col].dropna().unique().tolist())

    filtered_df = df.copy()
    if org != 'ã™ã¹ã¦':
        filtered_df = filtered_df[filtered_df[org_col] == org]
    if age != 'ã™ã¹ã¦':
        filtered_df = filtered_df[filtered_df[age_col] == age]
    if gender != 'ã™ã¹ã¦':
        filtered_df = filtered_df[filtered_df[gender_col] == gender]

    st.write(f"âš™ï¸ ãƒ•ã‚£ãƒ«ã‚¿å¾Œã®ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(filtered_df)} ä»¶")

    # --- å¯è¦–åŒ–: æ„Ÿæƒ…åˆ†å¸ƒ
    st.subheader("ğŸ“Š æ„Ÿæƒ…å‚¾å‘ï¼ˆå††ã‚°ãƒ©ãƒ•ï¼‰")
    sentiment_counts = filtered_df['sentiment'].value_counts()
    fig1, ax1 = plt.subplots()
    ax1.pie(sentiment_counts, labels=sentiment_counts.index, autopct='%1.1f%%')
    ax1.axis('equal')
    st.pyplot(fig1)

    # --- ã‚«ãƒ†ã‚´ãƒªåˆ¥é »å‡ºå˜èª
    st.subheader("ğŸ” åˆ†é¡åˆ¥é »å‡ºå˜èª")
    for cat in ['ç¶­æŒ', 'å¼·åŒ–', 'æ”¹å–„']:
        cat_df = filtered_df[filtered_df['category'] == cat]
        tokens = [token for tokens in cat_df['all_tokens'] for token in tokens]
        counter = Counter(tokens)
        if counter:
            show_wordcloud(counter, f"{cat}ã‚«ãƒ†ã‚´ãƒªã®WordCloudï¼ˆTop Wordsï¼‰")

    # --- å…ƒã®è¨˜è¿°ä¾‹
    st.subheader("ğŸ§¾ è¦æœ›ä¾‹ï¼ˆå…ƒæ–‡ä»˜ãï¼‰")
    ex_cat = st.selectbox("è¡¨ç¤ºã™ã‚‹ã‚«ãƒ†ã‚´ãƒª", ['ç¶­æŒ', 'å¼·åŒ–', 'æ”¹å–„', 'ãƒŸãƒƒã‚¯ã‚¹', 'ä¸æ˜'])
    ex_df = filtered_df[filtered_df['category'] == ex_cat].head(10)
    for idx, row in ex_df.iterrows():
        st.markdown(f"- **ID {idx}**: Q1: {row['Q1å›ç­”']} / Q2: {row['Q2å›ç­”']} / Q3: {row['Q3å›ç­”']}")

    # --- çµæœã®ä¿å­˜
    st.subheader("ğŸ’¾ åˆ†æçµæœã®ä¿å­˜")
    result_df = filtered_df.copy()
    csv = result_df.to_csv(index=False).encode('utf-8-sig')
    st.download_button("ğŸ“¥ CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", csv, file_name='analyzed_output.csv', mime='text/csv')